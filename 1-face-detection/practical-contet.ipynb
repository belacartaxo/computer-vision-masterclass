{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the image\n",
    "<b>Functions used:</b>\n",
    "- cv2.imread(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the image\n",
    "# - cv2.imread(path): Reads an image from the specified file.\n",
    "#   - `path` is the location of the image on your system (e.g., './imgs/people1.jpg').\n",
    "#   - The image is read in **BGR** (Blue, Green, Red) color format by default in OpenCV.\n",
    "#   - If the image cannot be read (wrong path or file type), it will return `None`.\n",
    "path_p1 = './imgs/people1.jpg'  # Define the path where the image is located\n",
    "image_p1 = cv2.imread(path_p1)  # Read the image from the specified path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing the image\n",
    "<b>Functions used:</b>\n",
    "- image.shape\n",
    "- cv2.imshow(\"window_name\", image)\n",
    "- cv2.waitKey(0)\n",
    "- cv2.destroyAllWindows()\n",
    "- cv2.resize(image, new_size)\n",
    "- cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image shape: (1280, 1920, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"original image shape:\", image_p1.shape)  \n",
    "# Returns the shape of the image as a tuple: (height, width, channels)\n",
    "# - height: Number of rows (pixels) in the image.\n",
    "# - width: Number of columns (pixels) in the image.\n",
    "# - channels: Number of color channels (e.g., 3 for RGB, 1 for grayscale)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image):\n",
    "    # Display the image in a window titled \"test\"\n",
    "    # - cv2.imshow(window_name, image): Opens a new window to display the image.\n",
    "    cv2.imshow(\"test\", image)\n",
    "\n",
    "    # Wait for the user to press any key before proceeding\n",
    "    # - cv2.waitKey(delay): Waits for a key press for a specified delay (in milliseconds).\n",
    "    #   - If delay=0, it waits indefinitely for a key press.\n",
    "    #   - The function returns the ASCII value of the key pressed.\n",
    "    # - Necessary in GUI-based applications to prevent the program from closing abruptly.\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    # Close all OpenCV windows\n",
    "    # - cv2.destroyAllWindows(): Closes all windows opened by OpenCV.\n",
    "    #   - Ensures no residual windows remain after the program ends.\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Call the function to display the image\n",
    "show_image(image_p1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to resize the image because it is too large and takes more time to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new image shape: (600, 800, 3)\n"
     ]
    }
   ],
   "source": [
    "# Resizing the image to a new size\n",
    "# - cv2.resize(image, size): Resizes the image to the specified size.+\n",
    "#   - `size` is the new size in the form of a tuple (width, height).\n",
    "#     In this case, we set the new size to 800x600 pixels.\n",
    "new_size = (800, 600)\n",
    "image_p1 = cv2.resize(image_p1, new_size)\n",
    "\n",
    "# Displaying the new image shape\n",
    "print(\"new image shape:\", image_p1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the image using the `show_image()` function\n",
    "show_image(image_p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When converting an image to grayscale, we reduce the amount of information:\n",
    "- The original image has 3 channels (BGR), so for an image of size 600x800, \n",
    "  the total number of pixels with 3 channels is 600 * 800 * 3 = 1,440,000.\n",
    "- When converting to grayscale, each pixel will only have one intensity value \n",
    "  (instead of 3 color channels), reducing the information to 600 * 800 = 480,000.\n",
    "- This reduces the data storage size significantly, making it faster to process, which is why grayscale images are preferred in tasks like face detection.\n",
    "\n",
    "\n",
    "<b>Note:</b> OpenCV works with BGR (Blue, Green, Red) as the default color order, which is the inverse of the more common RGB (Red, Green, Blue) used in many other libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the image to grayscale\n",
    "# - cv2.cvtColor(image, cv2.COLOR_BGR2GRAY): Converts the input image to grayscale.\n",
    "#   - `image`: The input image in BGR format (in OpenCV).\n",
    "#   - `cv2.COLOR_BGR2GRAY`: Specifies the color conversion code from BGR to grayscale.\n",
    "#     - BGR (Blue, Green, Red) is the color order used by OpenCV, as opposed to RGB.\n",
    "\n",
    "image_p1_gray = cv2.cvtColor(image_p1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Displaying the grayscale image using the `show_image()` function\n",
    "show_image(image_p1_gray)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Detecting faces\n",
    "<b>Functions used:</b>\n",
    "- cv2.CascadeClassifier(cascade_path)\n",
    "- face_detector.detectMultiScale(image) \n",
    "- cv2.rectangle(image, start_point, end_point, color, thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(path, new_size=None):\n",
    "    \"\"\"\n",
    "    This function loads an image from the given path, resizes it, and converts it to grayscale.\n",
    "    These functions were used earlier in separate steps.\n",
    "\n",
    "    Returns:\n",
    "    - image: The resized color image in BGR format.\n",
    "    - image_gray: The resized grayscale image.\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    image = cv2.imread(path)\n",
    "    \n",
    "    # # Resize the image to the specified size\n",
    "    # image = cv2.resize(image, new_size)\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Return both the color and grayscale images\n",
    "    return image, image_gray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the pre-trained Haar cascade classifier for face detection\n",
    "face_cascade_path = './classifiers/haarcascade_frontalface_default.xml'\n",
    "face_detector = cv2.CascadeClassifier(face_cascade_path) # Load the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each one of the rows represents a face detected\n",
      "Number of detections:  6\n",
      "[[390 323  56  56]\n",
      " [387 233  73  73]\n",
      " [ 92 239  66  66]\n",
      " [115 124  53  53]\n",
      " [475 123  59  59]\n",
      " [677  72  68  68]]\n"
     ]
    }
   ],
   "source": [
    "# Detect faces in the grayscale image\n",
    "# - detectMultiScale(image): Detects objects (faces) in the image.\n",
    "#   - `image_gray`: The image to be processed (in grayscale).\n",
    "#   - It returns a list of rectangles where faces are detected, in the format [x, y, w, h].\n",
    "#     - (x, y): The top-left corner of the face.\n",
    "#     - (w, h): The width and height of the detected face.\n",
    "\n",
    "detections_p1 = face_detector.detectMultiScale(image_p1_gray)\n",
    "\n",
    "# Print the number of faces detected and the coordinates\n",
    "print(\"Each one of the rows represents a face detected\")\n",
    "print(\"Number of detections: \", len(detections_p1))  # Print the number of detected faces\n",
    "print(detections_p1)  # Print the coordinates and sizes of the faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a rectangle around each detected face\n",
    "# - cv2.rectangle(image, start_point, end_point, color, thickness): Draws a rectangle on the image.\n",
    "#   - `start_point` is the top-left corner (x, y).\n",
    "#   - `end_point` is the bottom-right corner (x+w, y+h).\n",
    "#   - `color`: The rectangle color in BGR (green in this case: (0, 255, 0)).\n",
    "#   - `thickness`: The thickness of the rectangle border.\n",
    "image1_p1 = image_p1.copy()\n",
    "for (x, y, w, h) in detections_p1:\n",
    "    cv2.rectangle(image1_p1, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Draw a green rectangle around each face\n",
    "\n",
    "# Show the image with the detected faces and rectangles\n",
    "show_image(image1_p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note:</b> There might be detection errors for some faces, especially in the case of faces that are at extreme angles, partially hidden, or with poor lighting.\n",
    "In the next steps, we'll adjust some hyperparameters to improve the accuracy of the face detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Haarcascades Parameters \n",
    "\n",
    "### Parameters:\n",
    "\n",
    "**1. scaleFactor:**\n",
    "- It is a number that adjusts the scale of the image during the face detection process. It is used to \"scale\" the image to different sizes.\n",
    "- During detection, the algorithm starts with the original image size and then resizes it slightly to detect faces at different scales.\n",
    "- Typically, values are between 1.1 and 1.3. Larger values may detect faces at different sizes but can also increase the number of false positives.\n",
    "\n",
    "Example: If scaleFactor = 1.1, the image will be increased by 10% in each iteration to try and detect larger faces.\n",
    "\n",
    "**2. minNeighbors:**\n",
    "- This parameter controls how many neighbors a rectangle (face detection) needs to have to be considered a true face.\n",
    "- The algorithm detects many regions that might resemble a face, but not all are actual faces. The `minNeighbors` parameter helps filter out less reliable detections.\n",
    "- A higher value (e.g., 5 or 7) can reduce false positives, but it may also miss some real faces.\n",
    "\n",
    "Example: If minNeighbors = 7, the algorithm will require a detection to have 7 neighboring rectangles for it to be considered a real face.\n",
    "\n",
    "**3. minSize:**\n",
    "- The minimum size of faces to be detected, in pixels.\n",
    "- It defines the minimum size a face must have to be detected. If a face is smaller than the defined value, it will be ignored.\n",
    "  \n",
    "Example: If minSize = (20, 20), any face smaller than 20x20 pixels will be ignored.\n",
    "\n",
    "**4. maxSize:**\n",
    "- The maximum size of faces to be detected.\n",
    "- It defines the maximum size a face can be for detection. Faces larger than the specified value will be ignored.\n",
    "  \n",
    "Example: If maxSize = (100, 100), any face larger than 100x100 pixels will be ignored.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "# - `scaleFactor`: This compensates for the image size difference during detection. A value > 1.0 compensates for faces appearing at different sizes.\n",
    "#   - A common range is between 1.1 and 1.3.\n",
    "detections = face_detector.detectMultiScale(image_p1_gray, scaleFactor=1.09)\n",
    "\n",
    "image2_p1 = image_p1.copy()\n",
    "for (x, y, w, h) in detections:\n",
    "    cv2.rectangle(image2_p1, (x, y), (x + w, y + h), (0, 255, 0), 2)  \n",
    "\n",
    "show_image(image2_p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect faces in a given image (both color and grayscale)\n",
    "# The function performs face detection and returns an image with rectangles drawn around the detected faces.\n",
    "def detect_faces(image, image_gray, scaleFactor = 1.2, minNeighbors=7, minSize=(20,20), maxSize=(100,100)):\n",
    "    # - `minNeighbors`: Defines how many neighbors each rectangle should have to retain it as a face. A higher value reduces false positives.\n",
    "    # - `minSize` and `maxSize`: Defines the minimum and maximum sizes of the faces to be detected.\n",
    "    detections = face_detector.detectMultiScale(image_gray, scaleFactor=scaleFactor, minNeighbors=minNeighbors, minSize=minSize, maxSize=maxSize)\n",
    "    \n",
    "    image1 = image.copy()\n",
    "    for (x, y, w, h) in detections:\n",
    "        cv2.rectangle(image1, (x, y), (x + w, y + h), (0, 255, 0), 2) \n",
    "    return image1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the second image and preprocess it (resize and convert to grayscale)\n",
    "path_p2 = './imgs/people2.jpg'\n",
    "image_p2, image_p2_gray = load_and_preprocess_image(path_p2)\n",
    "\n",
    "# Detect faces in the second image and \n",
    "# display the result\n",
    "# `detect_faces()` will process the image and return it with rectangles drawn around the detected faces\n",
    "show_image(detect_faces(image_p2, image_p2_gray))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Eye detection with haarcascades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the pre-trained Haar cascade classifier for eye detection\n",
    "eye_cascade_path = './classifiers/haarcascade_eye.xml'\n",
    "eye_detector = cv2.CascadeClassifier(eye_cascade_path) # Load the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect eyes in a given image (both color and grayscale)\n",
    "# The function performs eye detection and returns an image with rectangles drawn around the detected eyes.\n",
    "def detect_eyes(image, image_gray, scaleFactor = 1.2, minNeighbors=7, minSize=(20,20), maxSize=(100,100)):\n",
    "    detections = eye_detector.detectMultiScale(image_gray, scaleFactor=scaleFactor, minNeighbors=minNeighbors, minSize=minSize, maxSize=maxSize)\n",
    "    image1 = image.copy()\n",
    "    for (x, y, w, h) in detections:\n",
    "        cv2.rectangle(image1, (x, y), (x + w, y + h), (0, 0, 255), 2) \n",
    "    return image1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the first image, with the original size\n",
    "image_p1_original, image_p1_gray_original = load_and_preprocess_image(path_p1)\n",
    "\n",
    "# Detect faces in the image: \n",
    "image_faces_detected = detect_faces(image_p1_original, image_p1_gray_original, 1.3, 7, (30, 30), (200, 200))\n",
    "\n",
    "# Now detect eyes within the detected faces:\n",
    "show_image(detect_eyes(image_faces_detected, image_p1_gray_original, 1.1, 10, (20, 20), (70, 70)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
